{"title":"深度学习笔记——线性回归","slug":"深度学习笔记——线性回归","date":"2018-11-30T13:00:00.000Z","updated":"2022-09-30T06:56:37.201Z","comments":true,"path":"api/articles/深度学习笔记——线性回归.json","excerpt":null,"covers":["https://oceaneyes.top/img/zhishigroup.jpg","https://oceaneyes.top/img/alipay.jpg","https://oceaneyes.top/img/wechatpay.jpg"],"content":"<link rel=\"stylesheet\" class=\"aplayer-secondary-style-marker\" href=\"/assets/css/APlayer.min.css\"><script src=\"/assets/js/APlayer.min.js\" class=\"aplayer-secondary-script-marker\"></script><p><em>深度学习通过基于神经网络模型逐级表示越来越抽象的概念或模式</em></p>\n<p><strong>单层神经网络：线性回归、Softmax回归</strong></p>\n<p>线性回归输出是一个连续值，适用于回归问题。</p>\n<p>​ 如：预测房屋价格、气温、销售额等连续值问题</p>\n<p>Softmax回归适用于分类问题，分类问题中的模型最终输出是一个离散值。</p>\n<p>​ 如：图像分类、垃圾邮件识别、疾病检测等输出离散值</p>\n<h2 id=\"线性回归\">线性回归</h2>\n<h3 id=\"线性回归基本要素\">线性回归基本要素</h3>\n<p>以房屋价格预测为例：假设价格只取决于 面积（平方米） 和房龄（年）</p>\n<h4 id=\"模型\">模型</h4>\n<p>设房屋面积为x1 ,房龄为x2 ， 售出价格为y 。建立基于输入x1,\nx2来计算输出y的表达式，即——模型（Model）</p>\n<p>线性回归假设输出与各个输入之间的线性关系：</p>\n<p>y‘ = x1w1 + x2w2 + b;</p>\n<p>其中w1;w2 是权重（weight），b\n是偏差（bias），且均为标量;是线性回归模型的参数（parameter）；模型输出y'是线性回归对真实价格y的预测／估计</p>\n<h4 id=\"模型训练\">模型训练</h4>\n<p>模型训练（model\ntraining）：通过数据寻找特定的模型参数值，使得模型在数据上误差尽可能小。</p>\n<h5 id=\"训练数据\">训练数据</h5>\n<ul>\n<li><p>训练数据集（training data set ）/ 训练集（training set）</p>\n<p>多栋房屋数据，真实出售价格 、面积、房龄</p></li>\n<li><p>样本（sample）</p>\n<p>一栋房屋</p></li>\n<li><p>标签（label）</p>\n<p>真实出售价格</p></li>\n<li><p>特征（feature）</p>\n<p>预测标签的两个因素叫做特征；（面积、房龄）</p>\n<p>特征用来表征样本的特点</p></li>\n</ul>\n<h5 id=\"损失函数\">损失函数</h5>\n<ul>\n<li>衡量价格测量值与真实值之间的误差</li>\n<li>通常选取一个非负数作为误差，且数值越小表示误差越小</li>\n</ul>\n<h5 id=\"优化算法\">优化算法</h5>\n<ul>\n<li>解析解（analytical solution）\n<ul>\n<li>当模型和损失函数较为简单时，误差最小化问题的解可直接用公式表达出来</li>\n</ul></li>\n<li>数值解（numerical solution）\n<ul>\n<li>大多数深度学习模型没有解析解，只能通过优化算法有限次迭代模型参数\n来尽可能降低损失函数的值</li>\n<li>常用：小批量随机梯度下降（ mini-batch stochastic gradient descent）\n<ul>\n<li>选取一组模型参数的初始值</li>\n<li>对参数进行多次迭代，使得每次迭代都可能降低损失函数的值</li>\n<li>每次迭代流程\n<ul>\n<li>先随机均匀采样\n一个由固定数目训练数据样本所组成的小批量（mini-batch）B</li>\n<li>求小批量中数据样本的平均损失有关模型参数的导数（梯度）</li>\n<li>用此结果与 预先设定的一个 正数的乘积\n作为模型参数在本次迭代的减小量</li>\n</ul></li>\n</ul></li>\n</ul></li>\n</ul>\n<h4 id=\"模型预测\">模型预测</h4>\n<p><em>模型预测、模型推断或模型测试</em></p>\n<p>模型训练完成后，将模型参数w1;w2; b 在优化算法停⽌时的值分别记作^ w1;\n^ w2;^b 。注意这⾥我们并不⼀定得到了最小化损失函数的最优解w1;w2; b\n，而是对最优解的⼀个近似。</p>\n<p>然后，就可以使⽤学出的线性回归模型x1 ^ w1 +x2 ^ w2 +^b\n来估算训练数据集以外任意⼀栋⾯积（平⽅⽶）房屋的价格了。</p>\n<h3 id=\"线性回归的表示方法\">线性回归的表示方法</h3>\n<p>线性回归与神经⽹络的联系，以及线性回归的⽮量计算表达式。</p>\n<h4 id=\"神经网络图\">神经网络图</h4>\n<h4 id=\"矢量计算表达式\">矢量计算表达式</h4>\n<hr>\n<h3 id=\"about-me\">About ME</h3>\n<h5 id=\"读书城南-在未来面前我们都是孩子\">👋 读书城南，🤔\n在未来面前，我们都是孩子～</h5>\n<ul>\n<li>📙\n一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~</li>\n</ul>\n<h5 id=\"social-media\">👋 Social Media</h5>\n<ul>\n<li><p>🛠️ Blog: <a href=\"http://oceaneyes.top\">http://oceaneyes.top</a></p></li>\n<li><p>⚡ PM导航: <a href=\"https://pmhub.oceangzy.top\">https://pmhub.oceangzy.top</a></p></li>\n<li><p>☘️ CNBLOG: <a href=\"https://www.cnblogs.com/oceaneyes-gzy/\">https://www.cnblogs.com/oceaneyes-gzy/</a></p></li>\n<li><p>🌱 AI PRJ自己部署的一些算法demo: <a href=\"http://ai.oceangzy.top/\">http://ai.oceangzy.top/</a></p></li>\n<li><p>📫 Email: 1450136519@qq.com</p></li>\n<li><p>💬 WeChat: <a href=\"https://oceaneyes.top/img/wechatqrcode.jpg\">OCEANGZY</a></p></li>\n<li><p>💬 公众号: <a href=\"https://oceaneyes.top/img/wechatgzh.jpeg\">UncleJoker-GZY</a></p></li>\n</ul>\n<h5 id=\"加入小组\">👋 加入小组~</h5>\n<p><img src=\"https://oceaneyes.top/img/zhishigroup.jpg\" title=\"加入组织\" alt width=\"240\"></p>\n<h5 id=\"感谢打赏\">👋 感谢打赏~</h5>\n<p><img src=\"https://oceaneyes.top/img/alipay.jpg\" title=\"支付宝打赏\" alt width=\"140\">\n<img src=\"https://oceaneyes.top/img/wechatpay.jpg\" title=\"微信打赏\" alt width=\"140\"></p>\n","more":"<p><em>深度学习通过基于神经网络模型逐级表示越来越抽象的概念或模式</em></p>\n<p><strong>单层神经网络：线性回归、Softmax回归</strong></p>\n<p>线性回归输出是一个连续值，适用于回归问题。</p>\n<p>​ 如：预测房屋价格、气温、销售额等连续值问题</p>\n<p>Softmax回归适用于分类问题，分类问题中的模型最终输出是一个离散值。</p>\n<p>​ 如：图像分类、垃圾邮件识别、疾病检测等输出离散值</p>\n<h2 id=\"线性回归\">线性回归</h2>\n<h3 id=\"线性回归基本要素\">线性回归基本要素</h3>\n<p>以房屋价格预测为例：假设价格只取决于 面积（平方米） 和房龄（年）</p>\n<h4 id=\"模型\">模型</h4>\n<p>设房屋面积为x1 ,房龄为x2 ， 售出价格为y 。建立基于输入x1,\nx2来计算输出y的表达式，即——模型（Model）</p>\n<p>线性回归假设输出与各个输入之间的线性关系：</p>\n<p>y‘ = x1w1 + x2w2 + b;</p>\n<p>其中w1;w2 是权重（weight），b\n是偏差（bias），且均为标量;是线性回归模型的参数（parameter）；模型输出y'是线性回归对真实价格y的预测／估计</p>\n<h4 id=\"模型训练\">模型训练</h4>\n<p>模型训练（model\ntraining）：通过数据寻找特定的模型参数值，使得模型在数据上误差尽可能小。</p>\n<h5 id=\"训练数据\">训练数据</h5>\n<ul>\n<li><p>训练数据集（training data set ）/ 训练集（training set）</p>\n<p>多栋房屋数据，真实出售价格 、面积、房龄</p></li>\n<li><p>样本（sample）</p>\n<p>一栋房屋</p></li>\n<li><p>标签（label）</p>\n<p>真实出售价格</p></li>\n<li><p>特征（feature）</p>\n<p>预测标签的两个因素叫做特征；（面积、房龄）</p>\n<p>特征用来表征样本的特点</p></li>\n</ul>\n<h5 id=\"损失函数\">损失函数</h5>\n<ul>\n<li>衡量价格测量值与真实值之间的误差</li>\n<li>通常选取一个非负数作为误差，且数值越小表示误差越小</li>\n</ul>\n<h5 id=\"优化算法\">优化算法</h5>\n<ul>\n<li>解析解（analytical solution）\n<ul>\n<li>当模型和损失函数较为简单时，误差最小化问题的解可直接用公式表达出来</li>\n</ul></li>\n<li>数值解（numerical solution）\n<ul>\n<li>大多数深度学习模型没有解析解，只能通过优化算法有限次迭代模型参数\n来尽可能降低损失函数的值</li>\n<li>常用：小批量随机梯度下降（ mini-batch stochastic gradient descent）\n<ul>\n<li>选取一组模型参数的初始值</li>\n<li>对参数进行多次迭代，使得每次迭代都可能降低损失函数的值</li>\n<li>每次迭代流程\n<ul>\n<li>先随机均匀采样\n一个由固定数目训练数据样本所组成的小批量（mini-batch）B</li>\n<li>求小批量中数据样本的平均损失有关模型参数的导数（梯度）</li>\n<li>用此结果与 预先设定的一个 正数的乘积\n作为模型参数在本次迭代的减小量</li>\n</ul></li>\n</ul></li>\n</ul></li>\n</ul>\n<h4 id=\"模型预测\">模型预测</h4>\n<p><em>模型预测、模型推断或模型测试</em></p>\n<p>模型训练完成后，将模型参数w1;w2; b 在优化算法停⽌时的值分别记作^ w1;\n^ w2;^b 。注意这⾥我们并不⼀定得到了最小化损失函数的最优解w1;w2; b\n，而是对最优解的⼀个近似。</p>\n<p>然后，就可以使⽤学出的线性回归模型x1 ^ w1 +x2 ^ w2 +^b\n来估算训练数据集以外任意⼀栋⾯积（平⽅⽶）房屋的价格了。</p>\n<h3 id=\"线性回归的表示方法\">线性回归的表示方法</h3>\n<p>线性回归与神经⽹络的联系，以及线性回归的⽮量计算表达式。</p>\n<h4 id=\"神经网络图\">神经网络图</h4>\n<h4 id=\"矢量计算表达式\">矢量计算表达式</h4>\n<hr>\n<h3 id=\"about-me\">About ME</h3>\n<h5 id=\"读书城南-在未来面前我们都是孩子\">👋 读书城南，🤔\n在未来面前，我们都是孩子～</h5>\n<ul>\n<li>📙\n一个热衷于探索学习新方向、新事物的智能产品经理，闲暇时间喜欢coding💻、画图🎨、音乐🎵、学习ing~</li>\n</ul>\n<h5 id=\"social-media\">👋 Social Media</h5>\n<ul>\n<li><p>🛠️ Blog: <a href=\"http://oceaneyes.top\">http://oceaneyes.top</a></p></li>\n<li><p>⚡ PM导航: <a href=\"https://pmhub.oceangzy.top\">https://pmhub.oceangzy.top</a></p></li>\n<li><p>☘️ CNBLOG: <a href=\"https://www.cnblogs.com/oceaneyes-gzy/\">https://www.cnblogs.com/oceaneyes-gzy/</a></p></li>\n<li><p>🌱 AI PRJ自己部署的一些算法demo: <a href=\"http://ai.oceangzy.top/\">http://ai.oceangzy.top/</a></p></li>\n<li><p>📫 Email: 1450136519@qq.com</p></li>\n<li><p>💬 WeChat: <a href=\"https://oceaneyes.top/img/wechatqrcode.jpg\">OCEANGZY</a></p></li>\n<li><p>💬 公众号: <a href=\"https://oceaneyes.top/img/wechatgzh.jpeg\">UncleJoker-GZY</a></p></li>\n</ul>\n<h5 id=\"加入小组\">👋 加入小组~</h5>\n<p><img src=\"https://oceaneyes.top/img/zhishigroup.jpg\" title=\"加入组织\" alt width=\"240\"></p>\n<h5 id=\"感谢打赏\">👋 感谢打赏~</h5>\n<p><img src=\"https://oceaneyes.top/img/alipay.jpg\" title=\"支付宝打赏\" alt width=\"140\">\n<img src=\"https://oceaneyes.top/img/wechatpay.jpg\" title=\"微信打赏\" alt width=\"140\"></p>\n","categories":[{"name":"Artificial Intelligence","path":"api/categories/Artificial Intelligence.json"},{"name":"Machine Learning","path":"api/categories/Machine Learning.json"},{"name":"Deep Learning","path":"api/categories/Deep Learning.json"}],"tags":[{"name":"Machine Learning","path":"api/tags/Machine Learning.json"},{"name":"Deep Learning","path":"api/tags/Deep Learning.json"}]}